{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "689c25c5b2f34bd38a121ba2a71cbbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b9b75ccedc54d7eaf656f4aa7524c7d",
              "IPY_MODEL_7962a4de10ce4eea81e15e5edc1a3a9f",
              "IPY_MODEL_5b05c20c8f69479c92a83ea7f300889e"
            ],
            "layout": "IPY_MODEL_2ef54f9f071d4a038eea94ff330aefad"
          }
        },
        "4b9b75ccedc54d7eaf656f4aa7524c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c021dc2b42741059bd52d52cd77ab94",
            "placeholder": "​",
            "style": "IPY_MODEL_472f6aeb04424c4b9f99baffcb3704c8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7962a4de10ce4eea81e15e5edc1a3a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07b1b7fb09be4155a1fa9b6fb3749ab1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10097680d2e64d40bebb381f7c469c2c",
            "value": 2
          }
        },
        "5b05c20c8f69479c92a83ea7f300889e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a2a376d7ab40f8bdb530ef63fb61f7",
            "placeholder": "​",
            "style": "IPY_MODEL_c5e197096f2d45dba00ab00ae7d1d132",
            "value": " 2/2 [00:34&lt;00:00, 16.24s/it]"
          }
        },
        "2ef54f9f071d4a038eea94ff330aefad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c021dc2b42741059bd52d52cd77ab94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472f6aeb04424c4b9f99baffcb3704c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07b1b7fb09be4155a1fa9b6fb3749ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10097680d2e64d40bebb381f7c469c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98a2a376d7ab40f8bdb530ef63fb61f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5e197096f2d45dba00ab00ae7d1d132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43O6G0HkIQnc",
        "outputId": "73809219-94b5-495c-cdca-e1ca94d01425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: bitsandbytes 0.41.1\n",
            "Uninstalling bitsandbytes-0.41.1:\n",
            "  Successfully uninstalled bitsandbytes-0.41.1\n",
            "\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/dist-packages/bitsandbytes-0.41.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/dist-packages/bitsandbytes-0.41.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting bitsandbytes==0.41.1\n",
            "  Using cached bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Using cached bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/dist-packages/bitsandbytes-0.41.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.1\n",
            "Requirement already satisfied: accelerate==0.27.2 in /usr/local/lib/python3.11/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.30.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "   # Create necessary directories\n",
        "   #!mkdir -p /content/cifar10_images\n",
        "   #!mkdir -p /content/output\n",
        "   #!mkdir -p /content/checkpoints\n",
        "\n",
        "   # Upload your files (you can do this manually through Colab's file upload interface)\n",
        "   # Make sure your files are in these locations:\n",
        "   # - /content/cifar10_images/ (containing all your CIFAR10 images)\n",
        "   # - /content/cifar10_qa.json (your JSON file with Q&A pairs)\n",
        "\n",
        "   # First, let's properly install bitsandbytes\n",
        "!pip uninstall -y bitsandbytes\n",
        "!pip install bitsandbytes==0.41.1\n",
        "!pip install accelerate==0.27.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pgaY-bHtY5IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   # Check if files are in the correct locations\n",
        "   import os\n",
        "   import json\n",
        "\n",
        "   # Check images\n",
        "   print(\"Images in cifar10_images folder:\")\n",
        "   print(os.listdir(\"/content/drive/MyDrive/Assignment_23/cifar10_images\"))\n",
        "\n",
        "   # Check JSON file\n",
        "   with open(\"/content/drive/MyDrive/Assignment_23/cifar10_qa_colab.json\", 'r') as f:\n",
        "       data = json.load(f)\n",
        "       print(\"\\nNumber of images in JSON:\", len(data))\n",
        "       print(\"\\nSample of first image data:\")\n",
        "       print(json.dumps(data[0], indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ9oAkjOIqr6",
        "outputId": "839ec8df-0b65-49c7-c53c-542c9f305ea2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images in cifar10_images folder:\n",
            "['CIFAR10_Sample4.png', 'CIFAR10_Sample5.png', 'CIFAR10_Sample2.png', 'CIFAR10_Sample3.png', 'CIFAR10_Sample1.png']\n",
            "\n",
            "Number of images in JSON: 5\n",
            "\n",
            "Sample of first image data:\n",
            "{\n",
            "  \"image_path\": \"CIFAR10_Sample1.png\",\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question\": \"What is the main object in the image?\",\n",
            "      \"answer\": \"A bird\"\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"What color is the main object?\",\n",
            "      \"answer\": \"Light brown body with a dark brown head\"\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"What is the position of the main object?\",\n",
            "      \"answer\": \"Facing to the right with wings folded\"\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"What color is the background?\",\n",
            "      \"answer\": \"A gradient of blue\"\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"What additional information is present in the image?\",\n",
            "      \"answer\": \"The image is labeled with the text 'Class: bird' at the top\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Updated imports (remove bitsandbytes for now)\n",
        "!pip install torch torchvision transformers accelerate peft datasets pillow sentencepiece\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoProcessor,\n",
        "    AutoModel,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, List, Tuple\n",
        "import numpy as np\n",
        "from datasets import Dataset as HFDataset\n",
        "import gc\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p11AWSyJIq7C",
        "outputId": "272ecef0-e45f-4096-adfe-fc8ad0f086bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.0.dev0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.27.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-ai73q5uk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ai73q5uk\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 953196a43dae6a3c474165fba7d215fcbc7b7730\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Configuration\n",
        "class Config:\n",
        "    # Model paths\n",
        "    SIGLIP_MODEL = \"google/siglip-so400m-patch14-384\"  # Using base SigLIP model\n",
        "    PHI3_MODEL = \"microsoft/Phi-3-mini-128k-instruct\"\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 4\n",
        "    LEARNING_RATE = 2e-4\n",
        "    NUM_EPOCHS = 3\n",
        "    WARMUP_STEPS = 100\n",
        "\n",
        "    # qLoRA parameters\n",
        "    LORA_R = 16\n",
        "    LORA_ALPHA = 32\n",
        "    LORA_DROPOUT = 0.05\n",
        "\n",
        "    # Data paths (Colab-specific)\n",
        "    IMAGE_DIR = \"/content/drive/MyDrive/Assignment_23/cifar10_images\"\n",
        "    QA_JSON_PATH = \"/content/drive/MyDrive/Assignment_23/cifar10_qa_colab.json\"\n",
        "\n",
        "    # Output paths\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/Assignment_23/output\"\n",
        "    CHECKPOINT_DIR = \"/content/drive/MyDrive/Assignment_23/checkpoints\""
      ],
      "metadata": {
        "id": "TkACYO5NKiOD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Updated dataset class for SigLIP\n",
        "class CIFAR10QADataset(Dataset):\n",
        "    \"\"\"Custom dataset class for CIFAR10 Q&A pairs\"\"\"\n",
        "\n",
        "    def __init__(self, image_dir: str, qa_json_path: str, processor):\n",
        "        self.image_dir = image_dir\n",
        "        self.processor = processor\n",
        "        self.data = self._load_data(qa_json_path)\n",
        "\n",
        "    def _load_data(self, qa_json_path: str) -> List[Dict]:\n",
        "        \"\"\"Load and process Q&A JSON file\"\"\"\n",
        "        with open(qa_json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict:\n",
        "        item = self.data[idx]\n",
        "        image_path = os.path.join(self.image_dir, item['image_path'])\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # Process image and text\n",
        "        inputs = self.processor(\n",
        "            images=image,\n",
        "            text=item['questions'][0]['question'],\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        # Convert to format expected by SigLIP\n",
        "        return {\n",
        "            'pixel_values': inputs['pixel_values'].squeeze(0),\n",
        "            'input_ids': inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(0) if 'attention_mask' in inputs else torch.ones_like(inputs['input_ids']).squeeze(0)\n",
        "        }"
      ],
      "metadata": {
        "id": "zkG1E4C_Krh4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Simplified model setup (without quantization)\n",
        "def setup_models(config: Config) -> Tuple[nn.Module, nn.Module]:\n",
        "    \"\"\"Initialize and setup SigLIP and Phi3 models\"\"\"\n",
        "\n",
        "    # Setup SigLIP\n",
        "    siglip_processor = AutoProcessor.from_pretrained(config.SIGLIP_MODEL)\n",
        "    siglip_model = AutoModel.from_pretrained(\n",
        "        config.SIGLIP_MODEL,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Setup Phi3 (frozen)\n",
        "    phi3_model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.PHI3_MODEL,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # Freeze Phi3 parameters\n",
        "    for param in phi3_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Setup Phi3 tokenizer\n",
        "    phi3_tokenizer = AutoTokenizer.from_pretrained(config.PHI3_MODEL)\n",
        "\n",
        "    return siglip_model, phi3_model, siglip_processor, phi3_tokenizer"
      ],
      "metadata": {
        "id": "GdPl89o9Ku9q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Updated training setup with compatible arguments\n",
        "def setup_training(config: Config, model: nn.Module, train_dataset: Dataset):\n",
        "    \"\"\"Setup training arguments and trainer\"\"\"\n",
        "\n",
        "    # Custom trainer class for SigLIP\n",
        "    class SigLIPTrainer(Trainer):\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                pixel_values=inputs['pixel_values'],\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask']\n",
        "            )\n",
        "\n",
        "            # Compute contrastive loss\n",
        "            logits_per_image = outputs.logits_per_image\n",
        "            logits_per_text = outputs.logits_per_text\n",
        "\n",
        "            # Create labels for contrastive learning (diagonal matrix)\n",
        "            batch_size = logits_per_image.shape[0]\n",
        "            labels = torch.arange(batch_size, device=logits_per_image.device)\n",
        "\n",
        "            # Compute loss\n",
        "            loss_img = torch.nn.functional.cross_entropy(logits_per_image, labels)\n",
        "            loss_txt = torch.nn.functional.cross_entropy(logits_per_text, labels)\n",
        "            loss = (loss_img + loss_txt) / 2\n",
        "\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=config.OUTPUT_DIR,\n",
        "        per_device_train_batch_size=config.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=4,\n",
        "        learning_rate=config.LEARNING_RATE,\n",
        "        num_train_epochs=config.NUM_EPOCHS,\n",
        "        warmup_steps=config.WARMUP_STEPS,\n",
        "        logging_dir='logs',\n",
        "        logging_steps=1,  # Log every step\n",
        "        save_strategy=\"steps\",  # Save more frequently\n",
        "        save_steps=10,\n",
        "        fp16=True,\n",
        "        remove_unused_columns=False,\n",
        "        optim=\"adamw_torch\",\n",
        "        gradient_checkpointing=True,\n",
        "        report_to=\"none\"  # Disable wandb\n",
        "    )\n",
        "\n",
        "    trainer = SigLIPTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "yI266OdvKxWE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Updated main function with verification\n",
        "def main():\n",
        "    # Initialize configuration\n",
        "    config = Config()\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "    os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "    # Setup models\n",
        "    print(\"Setting up models...\")\n",
        "    siglip_model, phi3_model, siglip_processor, phi3_tokenizer = setup_models(config)\n",
        "\n",
        "    # Setup dataset\n",
        "    print(\"Setting up dataset...\")\n",
        "    train_dataset = CIFAR10QADataset(\n",
        "        image_dir=config.IMAGE_DIR,\n",
        "        qa_json_path=config.QA_JSON_PATH,\n",
        "        processor=siglip_processor\n",
        "    )\n",
        "\n",
        "    # Setup training\n",
        "    print(\"Setting up training...\")\n",
        "    trainer = setup_training(config, siglip_model, train_dataset)\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the final model\n",
        "    final_model_path = os.path.join(config.OUTPUT_DIR, \"final_model\")\n",
        "    trainer.save_model(final_model_path)\n",
        "    print(\"Training completed and model saved!\")\n",
        "\n",
        "    # Verify the saved model\n",
        "    print(\"\\nVerifying saved model...\")\n",
        "    if os.path.exists(final_model_path):\n",
        "        print(f\"Model saved successfully at: {final_model_path}\")\n",
        "        print(\"Contents of saved directory:\")\n",
        "        print(os.listdir(final_model_path))\n",
        "\n",
        "        # Try loading the saved model\n",
        "        try:\n",
        "            saved_model = AutoModel.from_pretrained(final_model_path)\n",
        "            print(\"\\nSuccessfully loaded the saved model!\")\n",
        "            print(f\"Model type: {type(saved_model)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError loading saved model: {e}\")\n",
        "    else:\n",
        "        print(\"Model was not saved properly\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544,
          "referenced_widgets": [
            "689c25c5b2f34bd38a121ba2a71cbbaf",
            "4b9b75ccedc54d7eaf656f4aa7524c7d",
            "7962a4de10ce4eea81e15e5edc1a3a9f",
            "5b05c20c8f69479c92a83ea7f300889e",
            "2ef54f9f071d4a038eea94ff330aefad",
            "0c021dc2b42741059bd52d52cd77ab94",
            "472f6aeb04424c4b9f99baffcb3704c8",
            "07b1b7fb09be4155a1fa9b6fb3749ab1",
            "10097680d2e64d40bebb381f7c469c2c",
            "98a2a376d7ab40f8bdb530ef63fb61f7",
            "c5e197096f2d45dba00ab00ae7d1d132"
          ]
        },
        "id": "hePD1B2YKzAZ",
        "outputId": "66227a60-257a-49dd-92ef-7f8695187af4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.072cb7562cb8c4adf682a8e186aaafa49469eb5d.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.072cb7562cb8c4adf682a8e186aaafa49469eb5d.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "689c25c5b2f34bd38a121ba2a71cbbaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up dataset...\n",
            "Setting up training...\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:450: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='0' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [0/3 : < :, Epoch 0/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed and model saved!\n",
            "\n",
            "Verifying saved model...\n",
            "Model saved successfully at: /content/drive/MyDrive/Assignment_23/output/final_model\n",
            "Contents of saved directory:\n",
            "['config.json', 'model.safetensors', 'training_args.bin']\n",
            "\n",
            "Successfully loaded the saved model!\n",
            "Model type: <class 'transformers.models.siglip.modeling_siglip.SiglipModel'>\n"
          ]
        }
      ]
    }
  ]
}