# Multi-modal AI Models Assignment

This repository contains the implementation of a multi-modal AI system using SigLIP and Phi-3 models for image-text understanding and generation.


## Features

- SigLIP model for vision-language understanding
- Phi-3 model for text generation
- qLoRA fine-tuning implementation
- Contrastive learning for image-text matching

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Configure environment:
- Set up Google Colab with GPU runtime
- Configure Hugging Face authentication (optional)

## Usage

1. Run the main script:
```bash
python Assignment_23.py
```

## Requirements

- Python 3.8+
- PyTorch
- Transformers
- PEFT
- Bitsandbytes
- Other dependencies listed in requirements.txt

## License

MIT